{"cells":[{"cell_type":"markdown","source":["## 2. Preparing for Model Validation"],"metadata":{"id":"5fBP7YA-iHfV"},"id":"5fBP7YA-iHfV"},{"cell_type":"markdown","source":["#### 2.1 Calculating Regression Coefficients for all features"],"metadata":{"id":"wnbJw_YCJLgW"},"id":"wnbJw_YCJLgW"},{"cell_type":"markdown","source":["I will examine the coefficients and conduct a variable importance analysis to refine the feature coefficients. This was crucial in identifying which features were most impactful in predicting customer lifetime value (CLV). Despite these efforts, if the revised model exhibits high error rates, my next step will be to consider simplifying the calculation of customer lifespan (CLS). Instead of using weighted coefficients, I might revert to a more straightforward approach of multiplying [N_FirstRecency] by [N_YearlyFrequency]. This change would be based on the hypothesis that the inclusion of complex coefficients might be introducing unnecessary noise or distortion in the model, detracting from its predictive accuracy."],"metadata":{"id":"5u_tZIZAGt8D"},"id":"5u_tZIZAGt8D"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","\n","df = pd.read_csv('hotel_cluster_normalized.csv')\n","\n","# Split the data\n","X = df.drop(['CUSTOMER_ID', 'N_TotalRevenue'], axis=1)\n","y = df['N_TotalRevenue']\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Fit the model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Coefficients\n","coefficients = model.coef_\n","feature_importance = pd.DataFrame(coefficients, index=X.columns, columns=['Coefficient']).abs()\n","feature_importance.sort_values(by='Coefficient', ascending=False, inplace=True)\n","print(feature_importance)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"piajFuWnwXjj","executionInfo":{"status":"ok","timestamp":1699628573118,"user_tz":300,"elapsed":14202,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"outputId":"aa5c7974-a94c-402e-acf8-cbcbe961acf4"},"id":"piajFuWnwXjj","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                              Coefficient\n","N_FirstRecency                               1.606693e+09\n","N_Recency                                    1.279043e+09\n","N_LifetimeRecency                            1.182764e+09\n","Revenue_Segment_No Ancillary Spenders        3.729609e+08\n","Revenue_Segment_Low Ancillary Spenders       3.447274e+08\n","Revenue_Segment_Moderate Ancillary Spenders  2.730909e+08\n","Revenue_Segment_High Ancillary Spenders      1.531436e+08\n","Segment_No Ancillary Spenders                7.282971e+07\n","Segment_Low Ancillary Spenders               6.731529e+07\n","Segment_Moderate Ancillary Spenders          5.332184e+07\n","Segment_High Ancillary Spenders              2.994423e+07\n","N_FMonthlyBiasSD                             6.458193e-02\n","N_MMonthlyBiasSD                             6.345979e-02\n","N_FQuarterlyBiasSD                           1.181928e-02\n","N_MQuarterlyBiasSD                           1.172094e-02\n","N_Monetary                                   7.343400e-03\n","N_RecentMonetary                             2.380055e-03\n","PreferredProduct                             1.278464e-03\n","N_Frequency                                  1.100540e-03\n","N_PreferredProportion                        9.286322e-04\n","N_YearlyMonetary                             8.304919e-04\n","N_YearlyFrequency                            7.039319e-04\n","N_SDFrequency                                6.670014e-04\n","N_MProductBias                               5.733416e-04\n","N_AverageMonetary                            5.042606e-04\n","N_FMonthlyGrowth                             3.779551e-04\n","N_AverageFrequency                           2.340719e-04\n","N_MMonthlyGrowth                             2.174346e-04\n","N_MYearlyGrowth                              1.686015e-04\n","N_FProductBias                               1.164031e-04\n","N_MQuarterlyBias                             9.575017e-05\n","N_FYearlyGrowth                              8.840850e-05\n","Cluster                                      6.917119e-05\n","N_MMonthlyBias                               6.856212e-05\n","N_MonthlySD                                  2.435822e-05\n","N_FQuarterlyBias                             1.514852e-05\n","N_FMonthlyBias                               1.145784e-05\n"]}]},{"cell_type":"markdown","source":["#### 2.2 Testing the Revised Model for CLS Calculation with Coefficients (Post-Feature Importance Analysis) and Focusing on Customer Activity in 2021\n","##### In this phase, I tested a modified version of the CLS (Customer Lifespan) calculation model, incorporating coefficients derived from a feature importance analysis. This approach aimed to enhance the model's accuracy by weighting the most influential factors more heavily in the CLS computation.\n","##### Additionally, the scope of the analysis was narrowed to customers active in both 2021 and the preceding years. By focusing on this specific customer segment, the model's effectiveness in capturing consistent customer behavior over time was assessed. This approach provided insights into the reliability and predictability of the CLV (Customer Lifetime Value) model for customers with a demonstrated history of engagement."],"metadata":{"id":"QoYInEEOsQ4H"},"id":"QoYInEEOsQ4H"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load the original and normalized datasets\n","original_data = pd.read_csv('COLUMBIA_CAPSTONE_1M_FINAL_DATASET.csv', sep=\"|\", header=None)\n","normalized_data = pd.read_csv('/content/hotel_cluster_normalized.csv')\n","original_data.columns = ['CUSTOMER_ID', 'CALENDAR_YEAR', 'CALENDAR_MONTH', 'PRODUCT_CATEGORY',\n","                         'LATEST_TRANSACTION_DATE', 'NUM_TRANSACTIONS', 'TOTAL_SPEND', 'MARRIOTT_REVENUE']\n","\n","# Aggregate the original data by customer and year\n","yearly_data = original_data.groupby(['CUSTOMER_ID', 'CALENDAR_YEAR']).agg({\n","    'NUM_TRANSACTIONS': 'sum',\n","    'TOTAL_SPEND': 'sum'\n","}).reset_index()\n","\n","# Identify customers with transactions in 2021 and before 2021\n","customers_2021 = set(yearly_data[yearly_data['CALENDAR_YEAR'] == 2021]['CUSTOMER_ID'])\n","customers_before_2021 = set(yearly_data[yearly_data['CALENDAR_YEAR'] < 2021]['CUSTOMER_ID'])\n","active_customers = customers_2021.intersection(customers_before_2021)\n","\n","# Filter the yearly_data to include only these customers\n","filtered_yearly_data = yearly_data[yearly_data['CUSTOMER_ID'].isin(active_customers)]\n","\n","# Merge with normalized data\n","merged_2021 = pd.merge(filtered_yearly_data[filtered_yearly_data['CALENDAR_YEAR'] == 2021],\n","                       normalized_data, on='CUSTOMER_ID', how='left')\n","merged_2022 = pd.merge(filtered_yearly_data[filtered_yearly_data['CALENDAR_YEAR'] == 2022],\n","                       normalized_data, on='CUSTOMER_ID', how='left')\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Normalize features for both 2021 and 2022 datasets\n","features_to_normalize = ['NUM_TRANSACTIONS', 'TOTAL_SPEND']\n","for feature in features_to_normalize:\n","    merged_2021[feature] = scaler.fit_transform(merged_2021[[feature]])\n","    merged_2022[feature] = scaler.transform(merged_2022[[feature]])\n","\n","# Define functions to calculate CV and CLS\n","def calculate_customer_value(row):\n","    return row['N_TotalRevenue']\n","\n","def estimate_customer_lifespan_with_coefficients(row, recency_weight, frequency_weight):\n","    return (recency_weight * row['N_FirstRecency']) + (frequency_weight * row['N_YearlyFrequency'])\n","\n","# Extract weights from your regression model\n","regression_weights = {\n","    'N_FirstRecency': 1.606693e+09,\n","    'N_YearlyFrequency': 7.039319e-04\n","}\n","\n","# Calculate CV, CLS, and CLV for merged_2021 and merged_2022\n","merged_2021['CV'] = merged_2021.apply(calculate_customer_value, axis=1)\n","merged_2021['CLS'] = merged_2021.apply(lambda row: estimate_customer_lifespan_with_coefficients(row,\n","                                         regression_weights['N_FirstRecency'],\n","                                         regression_weights['N_YearlyFrequency']), axis=1)\n","merged_2021['CLV'] = merged_2021['CV'] * merged_2021['CLS']\n","\n","merged_2022['CV'] = merged_2022.apply(calculate_customer_value, axis=1)\n","merged_2022['CLS'] = merged_2022.apply(lambda row: estimate_customer_lifespan_with_coefficients(row,\n","                                         regression_weights['N_FirstRecency'],\n","                                         regression_weights['N_YearlyFrequency']), axis=1)\n","merged_2022['CLV'] = merged_2022['CV'] * merged_2022['CLS']\n","\n","# Calculate the high frequency threshold\n","high_frequency_threshold = normalized_data['N_YearlyFrequency'].quantile(0.75)\n","\n","# Define thresholds for segmentation\n","high_clv_threshold = merged_2021['CLV'].quantile(0.75)\n","long_cls_threshold = merged_2021['CLS'].quantile(0.75)\n","\n","# Function for customer segmentation with frequency\n","def categorize_customer_with_frequency(row, clv_threshold, cls_threshold, freq_threshold):\n","    frequency_segment = 'High Frequency' if row['N_YearlyFrequency'] >= freq_threshold else 'Low Frequency'\n","\n","    if row['CLV'] >= clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'High Value - Long Lifespan - {frequency_segment}'\n","    elif row['CLV'] >= clv_threshold and row['CLS'] < cls_threshold:\n","        return f'High Value - Short Lifespan - {frequency_segment}'\n","    elif row['CLV'] < clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'Low Value - Long Lifespan - {frequency_segment}'\n","    else:\n","        return f'Low Value - Short Lifespan - {frequency_segment}'\n","\n","# Apply segmentation with frequency\n","merged_2021['Customer_Segment'] = merged_2021.apply(lambda row: categorize_customer_with_frequency(row,\n","                                                                                                   high_clv_threshold,\n","                                                                                                   long_cls_threshold,\n","                                                                                                   high_frequency_threshold), axis=1)\n","merged_2022['Customer_Segment'] = merged_2022.apply(lambda row: categorize_customer_with_frequency(row,\n","                                                                                                   high_clv_threshold,\n","                                                                                                   long_cls_threshold,\n","                                                                                                   high_frequency_threshold), axis=1)\n","\n","# Validation\n","errors = merged_2022['TOTAL_SPEND'] - merged_2021['CLV']\n","mean_error = errors.mean()\n","median_error = errors.median()\n","percentile_25_error = errors.quantile(0.25)\n","percentile_50_error = errors.quantile(0.50)\n","percentile_75_error = errors.quantile(0.75)\n","positive_errors = (errors > 0).sum()\n","negative_errors = (errors < 0).sum()\n","\n","# Print validation metrics\n","print(\"Mean Error:\", mean_error)\n","print(\"Median Error:\", median_error)\n","print(\"25th Percentile of Error:\", percentile_25_error)\n","print(\"50th Percentile of Error:\", percentile_50_error)\n","print(\"75th Percentile of Error:\", percentile_75_error)\n","print(\"Number of Positive Errors (Underestimation):\", positive_errors)\n","print(\"Number of Negative Errors (Overestimation):\", negative_errors)\n"],"metadata":{"id":"v3p7gVuXIzm5","executionInfo":{"status":"ok","timestamp":1699636257171,"user_tz":300,"elapsed":30553,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"outputId":"a30fa44c-2286-4949-dbd0-0d05ed351985","colab":{"base_uri":"https://localhost:8080/"}},"id":"v3p7gVuXIzm5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Error: -23808783.22409544\n","Median Error: -12822339.505619768\n","25th Percentile of Error: -29050265.4783621\n","50th Percentile of Error: -12822339.505619768\n","75th Percentile of Error: -7105688.768388426\n","Number of Positive Errors (Underestimation): 0\n","Number of Negative Errors (Overestimation): 70442\n"]}]},{"cell_type":"markdown","source":["#### 2.3 Testing the Revised Model for CLS Calculation without Coefficients and Focusing on Customer Activity in 2021"],"metadata":{"id":"jlq_UsJ4KiET"},"id":"jlq_UsJ4KiET"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load the original and normalized datasets\n","original_data = pd.read_csv('COLUMBIA_CAPSTONE_1M_FINAL_DATASET.csv', sep=\"|\", header=None)\n","normalized_data = pd.read_csv('/content/hotel_cluster_normalized.csv')\n","original_data.columns = ['CUSTOMER_ID', 'CALENDAR_YEAR', 'CALENDAR_MONTH', 'PRODUCT_CATEGORY',\n","                         'LATEST_TRANSACTION_DATE', 'NUM_TRANSACTIONS', 'TOTAL_SPEND', 'MARRIOTT_REVENUE']\n","\n","# Aggregate the original data by customer and year\n","yearly_data = original_data.groupby(['CUSTOMER_ID', 'CALENDAR_YEAR']).agg({\n","    'NUM_TRANSACTIONS': 'sum',\n","    'TOTAL_SPEND': 'sum'\n","}).reset_index()\n","\n","# Identify customers with transactions in 2021 and before 2021\n","customers_2021 = set(yearly_data[yearly_data['CALENDAR_YEAR'] == 2021]['CUSTOMER_ID'])\n","customers_before_2021 = set(yearly_data[yearly_data['CALENDAR_YEAR'] < 2021]['CUSTOMER_ID'])\n","active_customers = customers_2021.intersection(customers_before_2021)\n","\n","# Filter the yearly_data to include only these customers\n","filtered_yearly_data = yearly_data[yearly_data['CUSTOMER_ID'].isin(active_customers)]\n","\n","# Merge with normalized data\n","merged_2021 = pd.merge(filtered_yearly_data[filtered_yearly_data['CALENDAR_YEAR'] == 2021],\n","                       normalized_data, on='CUSTOMER_ID', how='left')\n","merged_2022 = pd.merge(filtered_yearly_data[filtered_yearly_data['CALENDAR_YEAR'] == 2022],\n","                       normalized_data, on='CUSTOMER_ID', how='left')\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Normalize features for both 2021 and 2022 datasets\n","features_to_normalize = ['NUM_TRANSACTIONS', 'TOTAL_SPEND']\n","for feature in features_to_normalize:\n","    merged_2021[feature] = scaler.fit_transform(merged_2021[[feature]])\n","    merged_2022[feature] = scaler.transform(merged_2022[[feature]])\n","\n","# Calculate CV, CLS, and CLV for merged_2021 and merged_2022\n","merged_2021['CV'] = merged_2021['N_TotalRevenue']\n","merged_2021['CLS'] = merged_2021['N_FirstRecency'] * merged_2021['N_YearlyFrequency']\n","merged_2021['CLV'] = merged_2021['CV'] * merged_2021['CLS']\n","\n","merged_2022['CV'] = merged_2022['N_TotalRevenue']\n","merged_2022['CLS'] = merged_2022['N_FirstRecency'] * merged_2022['N_YearlyFrequency']\n","merged_2022['CLV'] = merged_2022['CV'] * merged_2022['CLS']\n","\n","# Calculate the high frequency threshold\n","high_frequency_threshold = normalized_data['N_YearlyFrequency'].quantile(0.75)\n","\n","# Define thresholds for segmentation\n","high_clv_threshold = merged_2021['CLV'].quantile(0.75)\n","long_cls_threshold = merged_2021['CLS'].quantile(0.75)\n","\n","# Function for customer segmentation with frequency\n","def categorize_customer_with_frequency(row, clv_threshold, cls_threshold, freq_threshold):\n","    frequency_segment = 'High Frequency' if row['N_YearlyFrequency'] >= freq_threshold else 'Low Frequency'\n","\n","    if row['CLV'] >= clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'High Value - Long Lifespan - {frequency_segment}'\n","    elif row['CLV'] >= clv_threshold and row['CLS'] < cls_threshold:\n","        return f'High Value - Short Lifespan - {frequency_segment}'\n","    elif row['CLV'] < clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'Low Value - Long Lifespan - {frequency_segment}'\n","    else:\n","        return f'Low Value - Short Lifespan - {frequency_segment}'\n","\n","# Apply segmentation with frequency\n","merged_2021['Customer_Segment'] = merged_2021.apply(lambda row: categorize_customer_with_frequency(row,\n","                                                                                                   high_clv_threshold,\n","                                                                                                   long_cls_threshold,\n","                                                                                                   high_frequency_threshold), axis=1)\n","merged_2022['Customer_Segment'] = merged_2022.apply(lambda row: categorize_customer_with_frequency(row,\n","                                                                                                   high_clv_threshold,\n","                                                                                                   long_cls_threshold,\n","                                                                                                   high_frequency_threshold), axis=1)\n","\n","# Validation\n","errors = merged_2022['TOTAL_SPEND'] - merged_2021['CLV']\n","mean_error = errors.mean()\n","median_error = errors.median()\n","percentile_25_error = errors.quantile(0.25)\n","percentile_50_error = errors.quantile(0.50)\n","percentile_75_error = errors.quantile(0.75)\n","positive_errors = (errors > 0).sum()\n","negative_errors = (errors < 0).sum()\n","\n","# Print validation metrics\n","print(\"Mean Error:\", mean_error)\n","print(\"Median Error:\", median_error)\n","print(\"25th Percentile of Error:\", percentile_25_error)\n","print(\"50th Percentile of Error:\", percentile_50_error)\n","print(\"75th Percentile of Error:\", percentile_75_error)\n","print(\"Number of Positive Errors (Underestimation):\", positive_errors)\n","print(\"Number of Negative Errors (Overestimation):\", negative_errors)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1699636420365,"user_tz":300,"elapsed":28268,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"FTpJHCG8wrcf","outputId":"194111df-1008-4353-bf3c-7e55db96ed32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Error: 0.0058793695168682025\n","Median Error: 0.004850446257223948\n","25th Percentile of Error: 0.004693186299018631\n","50th Percentile of Error: 0.004850446257223948\n","75th Percentile of Error: 0.005530977674585992\n","Number of Positive Errors (Underestimation): 69695\n","Number of Negative Errors (Overestimation): 747\n"]}],"id":"FTpJHCG8wrcf"},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Filter only those customers who are present in both 2021 and 2022 data\n","common_customers = set(merged_2021['CUSTOMER_ID']).intersection(set(merged_2022['CUSTOMER_ID']))\n","\n","# Filter both datasets to include only these common customers\n","merged_2021_common = merged_2021[merged_2021['CUSTOMER_ID'].isin(common_customers)]\n","merged_2022_common = merged_2022[merged_2022['CUSTOMER_ID'].isin(common_customers)]\n","\n","# Ensure the data is aligned by sorting based on CUSTOMER_ID\n","merged_2021_common.sort_values(by='CUSTOMER_ID', inplace=True)\n","merged_2022_common.sort_values(by='CUSTOMER_ID', inplace=True)\n","\n","# Predicting 2022 Total Spend based on 2021 data\n","X = merged_2021_common[['CV', 'CLS']]\n","y = merged_2022_common['TOTAL_SPEND']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate RMSE and R^2\n","rmse = mean_squared_error(y_test, y_pred, squared=False)\n","r_squared = r2_score(y_test, y_pred)\n","\n","print(\"RMSE:\", rmse)\n","print(\"R^2:\", r_squared)\n"],"metadata":{"id":"avq_8RTLT3r_","executionInfo":{"status":"ok","timestamp":1699638326927,"user_tz":300,"elapsed":654,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"outputId":"4f180105-d00a-4b54-e55b-bda934047acd","colab":{"base_uri":"https://localhost:8080/"}},"id":"avq_8RTLT3r_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 0.003570089517172678\n","R^2: 0.2638306292622018\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-63d6f2747833>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  merged_2021_common.sort_values(by='CUSTOMER_ID', inplace=True)\n"]}]},{"cell_type":"markdown","source":["The validation results indicate the following:\n","\n","Mean Error: The average difference between predicted CLV for 2021 and actual total spend in 2022 is approximately 0.0059. Since this is a small positive number, it suggests a slight overall underestimation.\n","\n","Median Error: The median error is also positive, around 0.0048, reinforcing the trend of underestimation.\n","\n","Percentile Errors: The 25th, 50th (median), and 75th percentile errors all align with this pattern of slight underestimation.\n","\n","Positive Errors (Underestimation): The majority of errors (69695 cases) are positive, meaning the model tends to underestimate the total spend.\n","\n","Negative Errors (Overestimation): A smaller number of cases (747) where the model overestimates the total spend.\n"],"metadata":{"id":"3s1StbJYGQ1U"},"id":"3s1StbJYGQ1U"},{"cell_type":"code","source":["merged_2021.head()"],"metadata":{"id":"tAcjjp6GK9sT","executionInfo":{"status":"ok","timestamp":1699636470871,"user_tz":300,"elapsed":238,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"outputId":"8cbe8363-695b-43d5-cf61-261959af0b78","colab":{"base_uri":"https://localhost:8080/","height":464}},"id":"tAcjjp6GK9sT","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   CUSTOMER_ID  CALENDAR_YEAR  NUM_TRANSACTIONS  TOTAL_SPEND  N_Recency  \\\n","0         3431           2021          0.000758     0.004722   0.948892   \n","1       333339           2021          0.009099     0.011231   0.995972   \n","2       353130           2021          0.006571     0.005258   0.996349   \n","3       353730           2021          0.049918     0.007090   0.995972   \n","4       353832           2021          0.001264     0.004743   0.956445   \n","\n","   N_Frequency  N_Monetary  N_FirstRecency  N_LifetimeRecency  \\\n","0     0.000752    0.004263        0.291918           0.240841   \n","1     0.008649    0.015008        0.500755           0.496790   \n","2     0.006643    0.006504        0.930514           0.926980   \n","3     0.052958    0.011403        0.931898           0.927987   \n","4     0.001253    0.006668        0.997231           0.953796   \n","\n","   N_YearlyFrequency  ...  Segment_No Ancillary Spenders  \\\n","0           0.001454  ...                              0   \n","1           0.017520  ...                              0   \n","2           0.013975  ...                              0   \n","3           0.046252  ...                              0   \n","4           0.008415  ...                              0   \n","\n","   Revenue_Segment_High Ancillary Spenders  \\\n","0                                        0   \n","1                                        0   \n","2                                        0   \n","3                                        0   \n","4                                        0   \n","\n","   Revenue_Segment_Low Ancillary Spenders  \\\n","0                                       1   \n","1                                       0   \n","2                                       1   \n","3                                       1   \n","4                                       1   \n","\n","   Revenue_Segment_Moderate Ancillary Spenders  \\\n","0                                            0   \n","1                                            1   \n","2                                            0   \n","3                                            0   \n","4                                            0   \n","\n","   Revenue_Segment_No Ancillary Spenders  Cluster        CV       CLS  \\\n","0                                      0        2  0.026720  0.000425   \n","1                                      0        0  0.046442  0.008773   \n","2                                      0        2  0.032179  0.013004   \n","3                                      0        4  0.035184  0.043103   \n","4                                      0        2  0.042502  0.008391   \n","\n","        CLV                             Customer_Segment  \n","0  0.000011  Low Value - Short Lifespan - High Frequency  \n","1  0.000407  High Value - Long Lifespan - High Frequency  \n","2  0.000418  High Value - Long Lifespan - High Frequency  \n","3  0.001517  High Value - Long Lifespan - High Frequency  \n","4  0.000357  High Value - Long Lifespan - High Frequency  \n","\n","[5 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-43704990-c44c-475d-b5a3-354299543e9d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER_ID</th>\n","      <th>CALENDAR_YEAR</th>\n","      <th>NUM_TRANSACTIONS</th>\n","      <th>TOTAL_SPEND</th>\n","      <th>N_Recency</th>\n","      <th>N_Frequency</th>\n","      <th>N_Monetary</th>\n","      <th>N_FirstRecency</th>\n","      <th>N_LifetimeRecency</th>\n","      <th>N_YearlyFrequency</th>\n","      <th>...</th>\n","      <th>Segment_No Ancillary Spenders</th>\n","      <th>Revenue_Segment_High Ancillary Spenders</th>\n","      <th>Revenue_Segment_Low Ancillary Spenders</th>\n","      <th>Revenue_Segment_Moderate Ancillary Spenders</th>\n","      <th>Revenue_Segment_No Ancillary Spenders</th>\n","      <th>Cluster</th>\n","      <th>CV</th>\n","      <th>CLS</th>\n","      <th>CLV</th>\n","      <th>Customer_Segment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3431</td>\n","      <td>2021</td>\n","      <td>0.000758</td>\n","      <td>0.004722</td>\n","      <td>0.948892</td>\n","      <td>0.000752</td>\n","      <td>0.004263</td>\n","      <td>0.291918</td>\n","      <td>0.240841</td>\n","      <td>0.001454</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.026720</td>\n","      <td>0.000425</td>\n","      <td>0.000011</td>\n","      <td>Low Value - Short Lifespan - High Frequency</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>333339</td>\n","      <td>2021</td>\n","      <td>0.009099</td>\n","      <td>0.011231</td>\n","      <td>0.995972</td>\n","      <td>0.008649</td>\n","      <td>0.015008</td>\n","      <td>0.500755</td>\n","      <td>0.496790</td>\n","      <td>0.017520</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.046442</td>\n","      <td>0.008773</td>\n","      <td>0.000407</td>\n","      <td>High Value - Long Lifespan - High Frequency</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>353130</td>\n","      <td>2021</td>\n","      <td>0.006571</td>\n","      <td>0.005258</td>\n","      <td>0.996349</td>\n","      <td>0.006643</td>\n","      <td>0.006504</td>\n","      <td>0.930514</td>\n","      <td>0.926980</td>\n","      <td>0.013975</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.032179</td>\n","      <td>0.013004</td>\n","      <td>0.000418</td>\n","      <td>High Value - Long Lifespan - High Frequency</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>353730</td>\n","      <td>2021</td>\n","      <td>0.049918</td>\n","      <td>0.007090</td>\n","      <td>0.995972</td>\n","      <td>0.052958</td>\n","      <td>0.011403</td>\n","      <td>0.931898</td>\n","      <td>0.927987</td>\n","      <td>0.046252</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.035184</td>\n","      <td>0.043103</td>\n","      <td>0.001517</td>\n","      <td>High Value - Long Lifespan - High Frequency</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>353832</td>\n","      <td>2021</td>\n","      <td>0.001264</td>\n","      <td>0.004743</td>\n","      <td>0.956445</td>\n","      <td>0.001253</td>\n","      <td>0.006668</td>\n","      <td>0.997231</td>\n","      <td>0.953796</td>\n","      <td>0.008415</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.042502</td>\n","      <td>0.008391</td>\n","      <td>0.000357</td>\n","      <td>High Value - Long Lifespan - High Frequency</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 46 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43704990-c44c-475d-b5a3-354299543e9d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-43704990-c44c-475d-b5a3-354299543e9d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-43704990-c44c-475d-b5a3-354299543e9d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-67b3e77e-52df-4e29-9daa-3c564cbcd243\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67b3e77e-52df-4e29-9daa-3c564cbcd243')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-67b3e77e-52df-4e29-9daa-3c564cbcd243 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["### 3. Analyze the overall customer segments\n","##### Aggregate Data for All Years: Instead of filtering data for specific years, I'll aggregate and analyze the data for all years available in the dataset.\n","\n","##### Calculate CLV for the Entire Dataset: Perform the calculations of CV, CLS, and CLV for the entire dataset.\n","\n","##### Segment Customers Based on the Entire Dataset: Apply the segmentation logic to the entire dataset."],"metadata":{"id":"1ZLznWAIPEAX"},"id":"1ZLznWAIPEAX"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load the original and normalized datasets\n","original_data = pd.read_csv('COLUMBIA_CAPSTONE_1M_FINAL_DATASET.csv', sep=\"|\", header=None)\n","normalized_data = pd.read_csv('/content/hotel_cluster_normalized.csv')\n","original_data.columns = ['CUSTOMER_ID', 'CALENDAR_YEAR', 'CALENDAR_MONTH', 'PRODUCT_CATEGORY',\n","                         'LATEST_TRANSACTION_DATE', 'NUM_TRANSACTIONS', 'TOTAL_SPEND', 'MARRIOTT_REVENUE']\n","\n","# Aggregate the original data by customer for all years\n","yearly_data = original_data.groupby(['CUSTOMER_ID']).agg({\n","    'NUM_TRANSACTIONS': 'sum',\n","    'TOTAL_SPEND': 'sum'\n","}).reset_index()\n","\n","# Merge with normalized data\n","merged_data = pd.merge(yearly_data, normalized_data, on='CUSTOMER_ID', how='left')\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Normalize features\n","features_to_normalize = ['NUM_TRANSACTIONS', 'TOTAL_SPEND']\n","for feature in features_to_normalize:\n","    merged_data[feature] = scaler.fit_transform(merged_data[[feature]])\n","\n","# Calculate CV, CLS, and CLV\n","merged_data['CV'] = merged_data['N_TotalRevenue']\n","merged_data['CLS'] = merged_data['N_FirstRecency'] * merged_data['N_YearlyFrequency']\n","merged_data['CLV'] = merged_data['CV'] * merged_data['CLS']\n","\n","# Calculate the high frequency threshold\n","high_frequency_threshold = normalized_data['N_YearlyFrequency'].quantile(0.75)\n","\n","# Define thresholds for segmentation\n","high_clv_threshold = merged_data['CLV'].quantile(0.75)\n","long_cls_threshold = merged_data['CLS'].quantile(0.75)\n","\n","# Function for customer segmentation with frequency\n","def categorize_customer_with_frequency(row, clv_threshold, cls_threshold, freq_threshold):\n","    frequency_segment = 'High Frequency' if row['N_YearlyFrequency'] >= freq_threshold else 'Low Frequency'\n","\n","    if row['CLV'] >= clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'High Value - Long Lifespan - {frequency_segment}'\n","    elif row['CLV'] >= clv_threshold and row['CLS'] < cls_threshold:\n","        return f'High Value - Short Lifespan - {frequency_segment}'\n","    elif row['CLV'] < clv_threshold and row['CLS'] >= cls_threshold:\n","        return f'Low Value - Long Lifespan - {frequency_segment}'\n","    else:\n","        return f'Low Value - Short Lifespan - {frequency_segment}'\n","\n","# Apply segmentation with frequency\n","merged_data['Customer_Segment'] = merged_data.apply(lambda row: categorize_customer_with_frequency(row,\n","                                                                                                   high_clv_threshold,\n","                                                                                                   long_cls_threshold,\n","                                                                                                   high_frequency_threshold), axis=1)\n","\n","# Explore the segments\n","segment_counts = merged_data['Customer_Segment'].value_counts()\n","print(segment_counts)\n"],"metadata":{"id":"Dii9wr-ZPKcz","executionInfo":{"status":"ok","timestamp":1699637225966,"user_tz":300,"elapsed":41226,"user":{"displayName":"Ya-Chien Yang","userId":"04285157822906654084"}},"outputId":"1e94befa-2a0f-41af-a78a-c4558f701463","colab":{"base_uri":"https://localhost:8080/"}},"id":"Dii9wr-ZPKcz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Low Value - Short Lifespan - Low Frequency      652203\n","High Value - Long Lifespan - High Frequency     152568\n","Low Value - Short Lifespan - High Frequency      96973\n","High Value - Long Lifespan - Low Frequency       96609\n","High Value - Short Lifespan - Low Frequency        653\n","Low Value - Long Lifespan - Low Frequency          534\n","Low Value - Long Lifespan - High Frequency         290\n","High Value - Short Lifespan - High Frequency       170\n","Name: Customer_Segment, dtype: int64\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"19xcVn-lh3z27f0Bhr8WjCy-eFNr2en2k","timestamp":1699638676204},{"file_id":"1E4B-al05uZcKPpnx_XxSjHEO02o2F0-b","timestamp":1699638467939},{"file_id":"1ecdTK2RDX9ir6vq6xu64KxSkamZJgogr","timestamp":1699622236172}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}